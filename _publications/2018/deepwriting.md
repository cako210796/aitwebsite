---
ref: deepwriting
title: "DeepWriting: Making Digital Ink Editable via Deep Generative Modeling"
authors: Emre Aksan, Fabrizio Pece, Otmar Hilliges
date: 2018-01-01
venue: "CHI '18"
image: /assets/projects/2018/deepwriting/animated_title.gif
external_project_page: 
video: /projects/2018/deepwriting/downloads/deepwriting_chi18.mp4
talk: 
paper: /assets/projects/2018/deepwriting/downloads/deepwriting_chi18.pdf
poster: 
data: 
code: https://github.com/emreaksan/deepwriting
conference_url: https://chi2018.acm.org
equal_contribution: 
award: "Honorable Mention Best Paper Award"
bibtex: "@inproceedings{Aksan:2018:DeepWriting,
	author = {Aksan, Emre and Pece, Fabrizio and Hilliges, Otmar},
	title = {{DeepWriting: Making Digital Ink Editable via Deep Generative Modeling}},
	booktitle = {SIGCHI Conference on Human Factors in Computing Systems},
	series = {CHI '18},
	year = {2018},
	location = {Montr√©al, Canada},
	publisher = {ACM},
	address = {New York, NY, USA},
}
"
---
Digital ink promises to combine the flexibility and aesthetics of handwriting and the ability to process, search and edit digital text.
        Character recognition converts handwritten text into a digital representation, albeit at the cost of losing  personalized appearance due to
        the technical difficulties of separating the interwoven components of content and style. In this paper, we propose a novel generative neural
        network architecture that is capable of disentangling style from content and thus making digital ink editable. Our model can synthesize arbitrary text,
        while giving users control over the visual appearance (style). For example, allowing for style transfer without changing the content, editing of digital ink
        at the word level and other application scenarios such as spell-checking and correction of handwritten text. We furthermore contribute a new dataset of
        handwritten text with fine-grained annotations at the character level and report results from an initial user evaluation.
