---
ref: human-performance-capture
title: "Human Performance Capture from Monocular Video in the Wild"
authors: Chen Guo, Xu Chen, Jie Song, Otmar Hilliges
date: 2021-01-01
venue: "2021 International Conference on 3D Vision (3DV)"
image: /assets/projects/2021/human-performance-capture/teaser.gif
external_project_page: 
video: https://youtu.be/5M7Ytnxmhd4
talk: 
paper: /assets/projects/2021/human-performance-capture/paper.pdf
poster: 
data: 
code: https://github.com/MoyGcc/hpcwild
conference_url: https://3dv2021.surrey.ac.uk/
equal_contribution: 
award: 
bibtex: "@inproceedings{guo2021human,
  title={Human Performance Capture from Monocular Video in the Wild},
  author={Guo, Chen and Chen, Xu and Song, Jie and Hilliges, Otmar},
  booktitle={2021 International Conference on 3D Vision (3DV)},
  pages={889--898},
  year={2021},
  organization={IEEE}
}"
---
Capturing the dynamically deforming 3D shape of clothed human is essential for numerous applications, including VR/AR, autonomous driving, and human-computer interaction. Existing methods either require a highly specialized capturing setup, such as expensive multi-view imaging systems, or they lack robustness to challenging body poses. In this work, we propose a method capable of capturing the dynamic 3D human shape from a monocular video featuring challenging body poses, without any additional input. We first build a 3D template human model of the subject based on a learned regression model. We then track this template model's deformation under challenging body articulations based on 2D image observations. Our method outperforms state-of-the-art methods on an in-the-wild human video dataset 3DPW. Moreover, we demonstrate its efficacy in robustness and generalizability on videos from iPER datasets.<hr/><br/><br/>
